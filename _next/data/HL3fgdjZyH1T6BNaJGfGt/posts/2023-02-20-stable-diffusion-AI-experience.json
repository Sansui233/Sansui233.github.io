{"pageProps":{"meta":{"title":"Stable Diffusion AI 绘画的实用经验与总结","date":"2023-02-21 08:00","tags":["AI"],"categories":"工具","description":"AI 画画现状","keywords":"AI绘画, stable-diffusion, AI绘图, AI画画"},"mdxcode":"\"use strict\";\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    h2: \"h2\",\n    h3: \"h3\",\n    hr: \"hr\",\n    img: \"img\",\n    li: \"li\",\n    p: \"p\",\n    ul: \"ul\",\n    ...props.components\n  };\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"2023-03-03：待大量补充和修订。\"\n    }), \"\\n\", _jsx(_components.hr, {}), \"\\n\", _jsx(_components.p, {\n      children: \"进阶经验，非科普。分为五个部分：模型选择，分辨率调整，采样方法，ControlNet，Lora概述。\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"此文章涉及多平台发布，由于生成类 AI 的争议，文中无外链推荐。\"\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"一、模型选择\",\n      children: \"一、模型选择\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"模型影响构图和笔触和色彩，决定成图的平均水平。社区经常都在换流行的模型，还是根据需求定，huggingface 和 civitai 上很多。\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"二次元目前主流三家 Anything Orange Counterfeit 。\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"目前有不少混合了 2D 和 3D 的 2.5D 模型，用来出 cos 的，个人不喜欢。\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"下图模型为 pastel-mix，图片画质已严重压缩（看不见则需要开代理，如果你用的 Innoreader 手机版阅读此文，大概率被放头图了）\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"https://cdn.jsdelivr.net/gh/NamiLing/upic/uPic/00153-2596022983-masterpiece,%20best%20quality,%20ultra-detailed,%20illustration,%201boy,%20Link%20in%20Breath%20of%20the%20wild,%20sun%20shine,water,%20on%20back,%20lying%20in%20wa.jpg\",\n        alt: \"pastel-mix\"\n      })\n    }), \"\\n\", _jsx(_components.h3, {\n      id: \"模型精度选择\",\n      children: \"模型精度选择\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"fp-16(2G)，fp-32(4G)，full(7G) 用于生产没有肉眼可见的区别。full 主要是训练用的。fp16 生产够用了，快，占用小。\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"bf-16(2G) 相对 fp-16 会损失一小部分细节，不推荐，会发布 bf-16 版本的模型也较少。\"\n    }), \"\\n\", _jsx(_components.h3, {\n      id: \"vae权重网络\",\n      children: \"VAE权重网络\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"影响色彩，主观效果是增加饱和度（比修图软件饱和度增强好太多）。目前流行的 VAE 就两个，一个 Waifu 的一个 Anything 的，很多带 vae 模型都是用的这两个改了个名字。\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"下图为 mix-pro-v3-fp16 模型，叠加了其配套的 WD vae 的 效果。\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"https://cdn.jsdelivr.net/gh/NamiLing/upic/uPic/00045-311454338-Original%20Characters,%201boy,%20sea%20shore,%20%20pastel-full.jpg\",\n        alt: \"Mix-pro-v3\"\n      })\n    }), \"\\n\", _jsx(_components.h3, {\n      id: \"prompt\",\n      children: \"Prompt\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"prompt（提示词）是玄学范围。不同模型的 prompt 词库不一，目前主流的词库有两个\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"适用 SD v1.x 及其衍生模型的 lexica\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"适用二次元模型的 Danbooru。\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"对于二次元模型，Prompt 指定物体，调整动作、指定颜色比较容易。取决于模型的泛化能力。\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Prompt 难以精确控制画风，所以尽管上限非常高，但主流越来越不倾向于用大量 Prompt 叠 buf，转成微调模型以达成精确需求。\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"在两个月前关于 Prompt 研究的文档就已经非常多了，这里不做推荐，因为不看文档，直接翻译成英文大概率是有效的。\"\n    }), \"\\n\", _jsx(_components.h3, {\n      id: \"文生图与图生图\",\n      children: \"文生图与图生图\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"文生图与图生图本质上没有什么不同，文生图只是将图片输入换成了一张随机的噪声图。\"\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"二、分辨率\",\n      children: \"二、分辨率\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"不同模型在生成时有最佳的分辨率，大部分都在 512px 左右，不超过 1024px。\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"提高分辨率不仅是单纯放大图片，AI 能够用模型细化图片。\"\n    }), \"\\n\", _jsx(_components.h3, {\n      id: \"图生图\",\n      children: \"图生图\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"img2img(图生图) 大部分时候被用来衍生，但是其效果最好的是将 txt2img 的低分辨率图放大（用同一个seed）。\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"在 web-ui 中，仅缩放(just-resize)为无 AI 的放大算法处理。 AI 放大使用的 Latent 方法即将被归入 Upscaler，也就是下面说的 Hires fix。\"\n    }), \"\\n\", _jsx(_components.h3, {\n      id: \"hires-fix\",\n      children: \"Hires fix\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Hires fix（高清修复）的作用是用 AI 从小图生成高分辨率图，处理用得好可以提高大幅提高图片上限。upscaler（放大器）可选几种放大方法，其中的 Latent 就是 SD 的画图方法，文生图与图生图均是这个方法。\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"在 web-ui 中， 默认只有 txt2img 可用，因为 img2img 本身就可以做图片放大。另外，有专门的 upscaler 选项卡。\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"使用 Latent upscaler (图生图) 放大到高分辨率图涉及局部重绘，部分模型支持较好，如 Pastel。但在 512 px 完成度就很高的模型上通常没有效果，或者更差（比如炫彩厚涂），这种用 GAN 类 Upscaler 直接放大比较好。\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"值得注意的是 web-ui 的 Hires fix 有两版算法，目前 txt2img 是新版， img2img是旧版，效果有一些小差别，很难比较好坏。\"\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"三、采样方法\",\n      children: \"三、采样方法\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Sampler（采样方法） 决定笔触和结构的稳定性。常用的有：\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"Euler a 是一个规整稳定的采样方法，出的图较平滑\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"DDIM 是一个过程不算稳定的采样方法，通常看起来比 Euler a 细节更多\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"DPM++ 2M Karas，最近在用的，过程稳定但有细节\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"有部分 Sampler 对高分辨率（1024px 以上）支持不好。\"\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"四、-controlnet\",\n      children: \"四、 ControlNet\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"ControlNet 目前是一个需要额外安装的插件，可以用于给线稿上色并细化，或从草图细化。\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"你的草图可以决定的是：\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"60%-100% 的线条位置（构图）\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"主要色块位置。需要搭配图生图，并且色块越碎越好，需要提前做好整体的光影效果。因为 大部分 AI 只会画整，会画碎的比较少（Pastel 会画碎）。\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"细化风格（画风）由模型决定，不由你的草稿决定。模型风格对于画风影响非常关键。Prompt 也可以影响画风。\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"细化内容（画的具体是什么）由 Prompt 、草稿、模型共同决定，调整 CFG、Denoise 、 ControlNet 的 Weight 可改变三者比例。\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"下图为自己的较草的线稿使用 ControlNet 与 Anything V3.0 上色：\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"https://cdn.jsdelivr.net/gh/NamiLing/upic/uPic/00275-3225619170-masterpiece,%20best%20quality,%20illustration,face,%20right%20hand,%20atomespheric,%20cold,%20sunshine,%20sky,,%20high%20detail,%20flowers%20and%20leafs.jpg\",\n        alt: \"Control-Net\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"（这个东西出名是因为某博说 ControlNet 初衷是洗稿……之前 Pixiv 也出过线稿上色的 AI，只是效果好和不好的差别，怎么没人说是搭配 PS 的线稿提取功能洗稿）\"\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"五、lora\",\n      children: \"五、Lora\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Lora 是一种训练小模型的方法，可以在 15 张图以上生成稳定的单个角色图。\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"已有大量角色图积累的流水线漫画苦力会比较省事，搭配 ControlNet 可生成固定姿势，或者使用线稿稳定地上色。但对于连续动作的细微差别不太行，细节演出表现依旧需要依赖线稿，或手动重绘\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"训练过程分为裁剪、自动打标、训练，最终生成约 100M 左右的 Lora 网络。Web-ui 已自带。\"\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"写在后面\",\n      children: \"写在后面\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"风格迁移渐渐成熟了，过拟合的问题在逐渐减少。减少过拟合的最终解决思路，还是把端到端的网络，按需求拆成了人为可控的 pipline。个人认为 AI 如果真的要作为工具，模块化的 pipline 是终点。\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"直接出成图的是对已有作品的模拟，抽抽卡，融入不到创意的工作流。\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"但是在发展好之前，地球可能已经枯竭了。\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"https://cdn.jsdelivr.net/gh/NamiLing/upic/uPic/00162-1748765688-masterpiece,%20best%20quality,%20ultra-detailed,%20illustration,%201boy,%20Link%20in%20Breath%20of%20the%20wild,%20stronde%20hair,%20sun%20shine,water,%20emotio.jpg\",\n        alt: \"pastel-mix\"\n      })\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = props.components || ({});\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","excerpt":" 2023-03-03：待大量补充和修订。  ------  进阶经验，非科普。分为五个部分：模型选择，分辨率调整，采样方法，ControlNet，Lora概述。  此文章涉及多平台发布，由于生成类 AI 的争议，文中无外链推荐。  ## 一、模型选择  模型影响构图和笔触和色彩，决定成","prevPost":{"title":"图像超分辨率工具推荐","link":"/posts/20230822-Super_resolution_models_and_tools"},"nextPost":{"title":"部署饥荒联机版Linux服务器","link":"/posts/dontstarvetogether-linux-server"},"headings":[{"title":"一、模型选择","rank":1,"id":"一、模型选择"},{"title":"模型精度选择","rank":2,"id":"模型精度选择"},{"title":"VAE权重网络","rank":2,"id":"vae权重网络"},{"title":"Prompt","rank":2,"id":"prompt"},{"title":"文生图与图生图","rank":2,"id":"文生图与图生图"},{"title":"二、分辨率","rank":1,"id":"二、分辨率"},{"title":"图生图","rank":2,"id":"图生图"},{"title":"Hires fix","rank":2,"id":"hires-fix"},{"title":"三、采样方法","rank":1,"id":"三、采样方法"},{"title":"四、 ControlNet","rank":1,"id":"四、-controlnet"},{"title":"五、Lora","rank":1,"id":"五、lora"},{"title":"写在后面","rank":1,"id":"写在后面"}]},"__N_SSG":true}